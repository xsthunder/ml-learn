{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a\n",
    "[【中文分词系列】 3. 字标注法与HMM模型 - 科学空间|Scientific Spaces](https://kexue.fm/archives/3922#Python%E5%AE%9E%E7%8E%B0)\n",
    "\n",
    "[一次性弄懂马尔可夫模型、隐马尔可夫模型、马尔可夫网络和条件随机场！(词性标注代码实现) - 知乎](https://zhuanlan.zhihu.com/p/74063873) 没啥用\n",
    "\n",
    "~~数据参考 https://github.com/pwxcoo/chinese-xinhua~~\n",
    "\n",
    "TODO\n",
    "1. 数据参考应该改成jieba的\n",
    "2. 重新写一个，并对比苏神的\n",
    "\n",
    "存在问题：\n",
    "1. 最后推出来的公式少了$P(O_1)$\n",
    "\n",
    "暂停：\n",
    "已经搞懂维提比和HMM，先看CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../data/chinese-xinhua-master/data/ci.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>264434.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.375156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.020124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  264434.000000\n",
       "mean        2.375156\n",
       "std         1.020124\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         2.000000\n",
       "75%         2.000000\n",
       "max        15.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "df = None\n",
    "with open(FILE_PATH, encoding='utf-8') as f:\n",
    "    \n",
    "    word = json.load(f)\n",
    "    l = [len(w['ci']) for w in word]\n",
    "    df = pd.DataFrame(l)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "import json\n",
    "hmm_model = {i:Counter() for i in 'sbme'}\n",
    "with open(FILE_PATH, encoding='utf-8') as f:\n",
    "    \n",
    "    word = json.load(f)\n",
    "    cnt = 1 # 没有词频，假设每个词都出现一次，待改进\n",
    "    for w in word:\n",
    "        w = w['ci']\n",
    "        \n",
    "        if len(w) == 1:\n",
    "            hmm_model['s'][w[0]] += cnt\n",
    "        else:\n",
    "            hmm_model['b'][w[0]] += cnt\n",
    "            hmm_model['e'][w[-1]] += cnt\n",
    "\n",
    "            for m in w[1:-1]:hmm_model['m'][m] += cnt\n",
    "#         break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm_model字典里面计算的是 $P(\\lambda_k|o_k)$ 的分子部分\n",
    "\n",
    "下面计算分母部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 5.805134968916488,\n",
       " 'b': 12.484090671145607,\n",
       " 'm': 11.5082746667548,\n",
       " 'e': 12.484090671145607}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_total = {i:log(sum(v.values())) for i,v in hmm_model.items()}; log_total # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "猜出来的$P(o_k|o_{k-1})$,即知道$o_{k-1}$，去枚举$o_k$，共bmes三种标签，因此有4*4 = 9项\n",
    "\n",
    "枚举$o_{k-1}$再枚举$o_{k}$，$\\forall o_{k-1} \\in bems, \\sum_{o_{k} \\in bems }{P(o_{k}|o_{k-1})} = 1, $\n",
    "1. b\n",
    "    1. ~~b~~\n",
    "    1. m 1\n",
    "    1. e 1\n",
    "    2. ~~s~~\n",
    "2. m\n",
    "    1. ~~b~~\n",
    "    2. m 1\n",
    "    3. e 1\n",
    "    4. ~~s~~\n",
    "3. e\n",
    "    1. b 1\n",
    "    2. ~~m~~\n",
    "    3. ~~e~~\n",
    "    4. s 1\n",
    "4. s\n",
    "    1. b 1\n",
    "    2. ~~m~~\n",
    "    3. ~~e~~\n",
    "    4. s 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = {'ss':0.3,\n",
    "    'sb':0.7,\n",
    "    'bm':0.3,\n",
    "    'be':0.7, \n",
    "    'mm':0.3,\n",
    "    'me':0.7,\n",
    "    'es':0.3,\n",
    "    'eb':0.7\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nodes\n",
    "\n",
    "是一个$ \\{ P(\\lambda_k|o_k) \\}$矩阵  \n",
    "\n",
    "列： $o_k \\in bems$ \n",
    "\n",
    "行：$\\lambda_k \\in input\\_string$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paths\n",
    "```json\n",
    "{'s': -5.805134968916488, 'b': -8.900571732689496, 'm': -7.770605048471433, 'e': -9.188253805141278}\n",
    "{'ss': -11.310269937832976, 'sb': -13.97830772741787, 'mm': -14.251491896513892, 'me': -14.939575202775782}\n",
    "{'sss': -16.122257726189517, 'ssb': -19.56800008436242, 'sbm': -23.57714448173857, 'sbe': -23.816488249508165}\n",
    "```\n",
    "\n",
    "\n",
    "```json\n",
    "// <bmes路径>[-1] 应该互不相同\n",
    "// <bmes路径>[-2:] in trans 才有效\n",
    "{\n",
    "<bmes路径>:叠加概率\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': -5.805134968916488, 'b': -8.900571732689496, 'm': -7.770605048471433, 'e': -9.188253805141278}\n",
      "{'ss': -11.310269937832976, 'sb': -13.97830772741787, 'mm': -14.251491896513892, 'me': -14.939575202775782}\n",
      "{'sss': -16.122257726189517, 'ssb': -19.56800008436242, 'sbm': -23.57714448173857, 'sbe': -23.816488249508165}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['我', '是', '傻', '逼']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49051492/index-generates-attributeerror-dict-values-object-has-no-attribute-index\n",
    "# python2 to python3\n",
    "import operator\n",
    "def get_key_by_max_value(d):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
    "    \"\"\"\n",
    "    return max(d.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "def viterbi(nodes):\n",
    "    paths = nodes[0]\n",
    "    for node in nodes[1:]: \n",
    "        # l 每个字\n",
    "        \n",
    "        paths_ = paths\n",
    "        print(paths)\n",
    "        paths = {}\n",
    "        for i,p_o in node.items():\n",
    "            # o_k 这个字的 bems\n",
    "            nows = {}\n",
    "            for path, path_p in paths_.items(): # 到 l - 1 为止 最大 的 <=4 维特比 路径 ；每条路径长度(paths的key) 是 j 即 nodes[0:j] 计算得到\n",
    "                \n",
    "                trans_key = path[-1] + i\n",
    "                current_path = path + i\n",
    "                \n",
    "                if trans_key in trans: # o_{i-1} + o{i}\n",
    "                    nows[ current_path ]= path_p + p_o + trans[trans_key]\n",
    "                    \n",
    "            k = get_key_by_max_value(nows) \n",
    "            \n",
    "            assert i == k[-1]\n",
    "            \n",
    "            paths[k] = nows[k]\n",
    "    return get_key_by_max_value(paths)\n",
    "\n",
    "def hmm_cut(s):\n",
    "    nodes = [{i:log(j[t]+1)-log_total[i] for i,j in hmm_model.items()} for t in s]\n",
    "    tags = viterbi(nodes)\n",
    "    words = [s[0]]\n",
    "    for i in range(1, len(s)):\n",
    "        if tags[i] in ['b', 's']:\n",
    "            words.append(s[i])\n",
    "        else:\n",
    "            words[-1] += s[i]\n",
    "    return words\n",
    "(hmm_cut('我是傻逼'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [b, e, m, s]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "hmm_model = {i:Counter() for i in 'sbme'}\n",
    "\n",
    "with open('dict.txt') as f:\n",
    "    for line in f:\n",
    "    lines = line.decode('utf-8').split(' ')\n",
    "    if len(lines[0]) == 1:\n",
    "    hmm_model['s'][lines[0]] += int(lines[1])# 应该是频次吧\n",
    "    else:\n",
    "    hmm_model['b'][lines[0][0]] += int(lines[1])\n",
    "    hmm_model['e'][lines[0][-1]] += int(lines[1])\n",
    "    for m in lines[0][1:-1]:\n",
    "    hmm_model['m'][m] += int(lines[1])\n",
    "\n",
    "log_total = {i:log(sum(hmm_model[i].values())) for i in 'sbme'}\n",
    "\n",
    "trans = {'ss':0.3,\n",
    "    'sb':0.7,\n",
    "    'bm':0.3,\n",
    "    'be':0.7, \n",
    "    'mm':0.3,\n",
    "    'me':0.7,\n",
    "    'es':0.3,\n",
    "    'eb':0.7\n",
    " }\n",
    "\n",
    "trans = {i:log(j) for i,j in trans.iteritems()}\n",
    "\n",
    "def viterbi(nodes):\n",
    "    paths = nodes[0]\n",
    "    for l in range(1, len(nodes)):\n",
    "        paths_ = paths\n",
    "        paths = {}\n",
    "        for i in nodes[l]:\n",
    "            nows = {}\n",
    "            for j in paths_:\n",
    "            if j[-1]+i in trans:\n",
    "                nows[j+i]= paths_[j]+nodes[l][i]+trans[j[-1]+i]\n",
    "            k = nows.values().index(max(nows.values()))\n",
    "            paths[nows.keys()[k]] = nows.values()[k]\n",
    "    return paths.keys()[paths.values().index(max(paths.values()))]\n",
    "\n",
    "def hmm_cut(s):\n",
    "    nodes = [{i:log(j[t]+1)-log_total[i] for i,j in hmm_model.iteritems()} for t in s]\n",
    "    tags = viterbi(nodes)\n",
    "    words = [s[0]]\n",
    "    for i in range(1, len(s)):\n",
    "        if tags[i] in ['b', 's']:\n",
    "            words.append(s[i])\n",
    "        else:\n",
    "            words[-1] += s[i]\n",
    "    return words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
